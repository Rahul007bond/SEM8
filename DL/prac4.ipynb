{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fc10a6-ac5c-484c-8b1f-14ac9f8f5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d75e9e-1ff8-43fe-a976-a357e08aea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceeacc3a-5008-4a28-9b6b-627b140c0072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325.25]\n",
      " [331.27]\n",
      " [329.83]\n",
      " ...\n",
      " [793.7 ]\n",
      " [783.33]\n",
      " [782.75]]\n"
     ]
    }
   ],
   "source": [
    "train = data_train.loc[:,[\"Open\"]].values\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b70306-0a4f-454a-adb5-ba5c705de547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368]\n",
      " [0.09701243]\n",
      " [0.09433366]\n",
      " ...\n",
      " [0.95725128]\n",
      " [0.93796041]\n",
      " [0.93688146]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "print(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8543aee-206d-48c6-a84e-3fee975a9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data structure with 50 timesteps and 1 output\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "timesteps = 5\n",
    "\n",
    "for i in range(timesteps, 1258):\n",
    "    x_train.append(train_scaled[i - timesteps:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed5bcdb-dc8a-46d2-ac60-286fade5d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.08581368]\n",
      "  [0.09701243]\n",
      "  [0.09433366]\n",
      "  [0.09156187]\n",
      "  [0.07984225]]\n",
      "\n",
      " [[0.09701243]\n",
      "  [0.09433366]\n",
      "  [0.09156187]\n",
      "  [0.07984225]\n",
      "  [0.0643277 ]]\n",
      "\n",
      " [[0.09433366]\n",
      "  [0.09156187]\n",
      "  [0.07984225]\n",
      "  [0.0643277 ]\n",
      "  [0.0585423 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.96294367]\n",
      "  [0.96123223]\n",
      "  [0.95475854]\n",
      "  [0.95204256]\n",
      "  [0.95163331]]\n",
      "\n",
      " [[0.96123223]\n",
      "  [0.95475854]\n",
      "  [0.95204256]\n",
      "  [0.95163331]\n",
      "  [0.95725128]]\n",
      "\n",
      " [[0.95475854]\n",
      "  [0.95204256]\n",
      "  [0.95163331]\n",
      "  [0.95725128]\n",
      "  [0.93796041]]]\n",
      "[0.0643277  0.0585423  0.06568569 ... 0.95725128 0.93796041 0.93688146]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc0cbe-6534-4ae1-bd75-9567ab640bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul Rajpurohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0037\n",
      "Epoch 2/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 3/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 7.9412e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 7.4299e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.0414e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 8.9953e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 7.4812e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 8.4779e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.3685e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 5.1304e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.8265e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 6.5338e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.7997e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.7185e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 4.9356e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 6.4300e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 4.3341e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.2890e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 4.6784e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.0032e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 5.0320e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.9948e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 4.7857e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.5227e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 4.5858e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 5.6735e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.2016e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0639e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.4350e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.5187e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 6.3518e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 4.5242e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 4.6436e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.3024e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 4.4472e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 4.6757e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 4.9527e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 4.7187e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 3.3500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 3.9120e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 3.2247e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m 483/1253\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 3.5296e-04"
     ]
    }
   ],
   "source": [
    "# Create RNN Model\n",
    "\n",
    "# Importing the Keras Libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout\n",
    "\n",
    "# initialisinig the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding the first RNN layer and some Dropout regularisation \n",
    "regressor.add(SimpleRNN(units = 100, activation=\"relu\", return_sequences=True ,input_shape = (x_train.shape[1], 1)))\n",
    "\n",
    "# adding the second RNN layer and some Dropout regularisation \n",
    "regressor.add(SimpleRNN(units = 100, activation=\"relu\", return_sequences=True))\n",
    "\n",
    "# adding the third RNN layer and some Dropout regularisation \n",
    "regressor.add(SimpleRNN(units = 100 , activation=\"relu\", return_sequences=True))\n",
    "\n",
    "# adding the fourth RNN layer and some Dropout regularisation \n",
    "regressor.add(SimpleRNN(units = 100))\n",
    "\n",
    "# Adding thw output Layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer= \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(x_train, y_train, epochs = 50, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4735d-456a-49df-8150-6f62bb20384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the real stock price of 2017\n",
    "\n",
    "data_test = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529695a-57de-484d-a2a7-191aa99e76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = data_test.loc[:, [\"Open\"]].values\n",
    "print(real_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564d321-7b98-4498-91c0-b8542fce88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "\n",
    "data_total = pd.concat((data_train[\"Open\"], data_test[\"Open\"]), axis = 0)\n",
    "inputs = data_total[len(data_total) - len(data_test) - timesteps:].values.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs) # min max scaler\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4c806-1429-44d1-8cee-c6a8184745ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(timesteps, 70):\n",
    "    if len(inputs[i-timesteps:i, 0]) == timesteps:\n",
    "        x_test.append(inputs[i-timesteps:i, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "predicte_stock_price = regressor.predict(x_test)\n",
    "predicte_stock_price = scaler.inverse_transform(predicte_stock_price)\n",
    "\n",
    "# visualising the results\n",
    "plt.plot(real_stock_price, color = \"red\", label = \"Real Google Stock Price\")\n",
    "plt.plot(predicte_stock_price, color = \"blue\", label = \"Predicted Google Stock Price\")\n",
    "plt.title(\"Google Stock Price prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Google Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9b3ea-54a3-4b13-adad-41ae36bbe2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
